% !TeX spellcheck = de_DE

\chapter{Methodology}
\label{chap:k2}

The following sections describe the principles of 3D lane marking reconstruction method proposed in this thesis. 
% with respect to their location in the processing chain (Fig.1.).

Section~\ref{sec:2.1} describes how lane markings are extracted.
Section~\ref{sec:2.2} describes the principle of line fitting, including line equation in two-point form and linear regression.
Section~\ref{sec:2.3} introduces the geometric properties of aerial images and their mathematical models, including collinearity equation and lens distortion correction. 
Section~\ref{sec:2.4} elaborates the usage of linear regression on 3D lane marking reconstruction, modeled through Least-Squares Adjustment. This is the key approach to solve the non-textured-neighboring quasi-infinite line reconstruction problem.




Fig. 1. Processing chain



\section{Extraction of Lane markings}
\label{sec:2.1}
[This is done with Halcon11/C...]



\section{Line Fitting}
\label{sec:2.2}

Line fitting is the process of constructing a straight line of infinite length that has the best fit to a two-dimensional dataset.

In this work, orthogonal regression model is presented based on line equation of two-point form.

Given a data set $\{x_i,y_i\}^n_{i=1}$ of $n$ points on a 2D plane, a linear regression model assumes that the relationship between the dependent variable $y_i$ and the regressors $x_i$ is linear. This relationship is modeled through a error variable $e_i$ -an unobserved random variable that adds noise to the linear relationship between the dependent variable and regressors.
Thus the model takes the form
\begin{equation} \label{eq:2.2}
y = \dfrac{(y_2-y_1)}{(x_2-x_1)}\times x-\dfrac{(y_2-y_1)}{(x_2-x_1)}\times x_1+y_1
\end{equation}

Line Equation in two-point form:
\begin{equation} \label{eq:2.1}
y-y_1 = \dfrac{(y_2-y_1)}{(x_2-x_1)}\times(x-x_1)
\end{equation}
where two points $(x_1,y_1)$ and $(x_2,y_2)$ define the infinite line with $x_2\neq x_1$ and $(x,y)$ is any point on the line.


\section{Geometric Properties of Aerial Photographs}
\label{sec:2.3}

This section describes the geometric model of the projection of 3D points into the image generated by a real camera. We first restrict the discussion to central perspective projection, i.e. cameras who have a single viewpoint and a planar sensor and being straight line-preserving. In subsection 2.1.1 the collinearity equation originate from. We then model deviations from this model, addressing real cameras with imperfect lenses, in subsection 2.1.2.

\subsection{Collinearity Equation}

Assuming frame photography, i.e. photographs exposed in one instant, and central projection model, i.e. cameras having a single viewpoint, and.
p.43

Our discussion on geometric properties focuses on central cameras, i.e.

Collinearity indicates the condition that the image point (on the sensor plate of the camera), the observed point (on the object) and the projection center of the camera were aligned at the moment the picture was taken. Every measured point leads to two collinearity equations, describing transformations from object space to image coordinates:
\begin{equation} \label{eq:2.3}
\begin{aligned}
x - x_0 = -c \dfrac {R_{11}(X-X_0) + R_{21}(Y-Y_0) + R_{31}(Z-Z_0)} {R_{13}(X-X_0) + R_{23}(Y-Y_0) + R_{33}(Z-Z_0)} \\
y - y_0 = -c \dfrac {R_{12}(X-X_0) + R_{22}(Y-Y_0) + R_{32}(Z-Z_0)} {R_{13}(X-X_0) + R_{23}(Y-Y_0) + R_{33}(Z-Z_0)}
\end{aligned}
\end{equation}
where\newline

$(x, y)$: image coordinates of the point \newline
$(x_0, y_0)$: image coordinates of principal point \newline
$c$: principal distance \newline
$(X, Y, Z)$: object coordinates of the point \newline
$(X_0, Y_0, Z_0)$: object coordinates of projection center \newline
$R_{11}$~$R_{33}$: elements of the rotation matrix R (3$\times$3-matrix orthogonal matrix from object space to image space, with 3 independent angles $\omega$, $\phi$ and $\kappa$\newline

The exterior orientations: $X_0$, $Y_0$, $Z_0$, $\omega$, $\phi$, $\kappa$ as well as the interior orientations: $x_0$, $y_0$, $c$ are the known elements in this work. The image coordinates $x,y$ are the measurements.


The collinearity model as presented here can be expanded to include parameters of
the interior orientation.

\subsection{Lens Distortion Correction}

Assuming $x$ and $y$ to be the distorted image coordinates, the corrections $\delta x$ and $\delta y$ are then calculated by the following equations
\begin{equation} \label{eq:2.2}
\begin{aligned}
\Delta x = x_p + A_1x_*(r^2-R_0^2) + A_2x_*(r^4-R_0^4) + B_1(r^2+2x_*^2) + B_22x_*y+C_2y \\
\Delta y = y_p + A_1y  (r^2-R_0^2) + A_2y  (r^4-R_0^4) + B_1(r^2+2y^2)   + B_22x_*y
\end{aligned}
\end{equation}
with $r=\sqrt{x_*^2+y^2}$ and $x_*=\dfrac{x}{C_1}$. The undistorted image coordinates $x\prime$ and $y\prime$ are then calculated by $x’=x+\Delta x$ and $y’=y+\Delta y$. [F. Kurz et al 2012] 



\section{Least-Squares Adjustment Model}
\label{sec:2.4}



%\begin{equation}\label{eq:test}
%a = b + c.
%\end{equation}

%\begin{equation}
%a = b + c. \tag{\ref{eq:test} revisited}
%\end{equation}

\section{}



\section{}


