% !TeX spellcheck = de_DE

\chapter{Introduction}

\section{Motivation}
The availability of large-scale, accurate high resolution 3D information of roads with lane markings and road furniture plays an important role towards autonomous driving. Aerial imagery is a valuable database to derive 3D information of roads even in areas difficult to access, like on motorways. Compared to optical satellite data, acquiring large-scale 3D lane markings by optical aerial imagery is more efficient and has higher accuracy and spatial resolution. In view of the fact, that in Germany exists no area-wide, high resolution 3D information of the road surfaces including lane markings, new methods to derive this information are demanded.

The standard workflow with aerial images would be to project the images onto a DSM and to derive the information in the projected imagery, but the generation of Digital Surface Model (DSM) from stereo images is challenging in the regions with low textures. The lane markings, for example, are the most visible texture on asphalt roads useful for 3D reconstruction. Thus, it is desired to improve the quality of the DSM on the road surfaces by exploiting the line character of the lane markings. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Autonomous Driving}

Autonomous driving is an important part of future transportation systems, and the execution of dynamic driving task is a key issue towards autonomous driving. According to the definition given by Society of Automotive Engineers (SAE) International, dynamic driving task includes the operational (e.g. steering, braking, accelerating, monitoring the vehicle and roadway) and tactical (responding to events, determining when to change lanes, turn, use signals, etc.) aspects. In the information report J3016 \cite{SAE2014} proposed by \citeauthor{SAE2014}, driving automation is identified into 6 levels from “no automation” to “full automation” as expressed in \cref{tab:SAElevel}. 

For autonomous driving, redundant sources of information for the driving environment are useful for increasing the robustness and availability of the system \cite{Aeberhard2015}. It is especially important for level 3, 4 and 5 driving automations where the execution of dynamic driving tasks is totally conducted by the system. 3D lane markings, for example, provide global environment information and can be used on supporting lane-accurate localization.


\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}
\definecolor{ballblue}{rgb}{0.13, 0.67, 0.8}
\begin{table}
	\centering
	\renewcommand{\arraystretch}{1.1}
%	\setlength{\arrayrulewidth}{1.2pt}
	\begin{tabular}{|>{\centering}m{0.7cm}|>{\centering}m{2cm}|l|l|l|l|}
		\hline
		\multicolumn{1}{|m{0.7cm}|}{SAE level} & 
		Name & 
		\multicolumn{1}{m{2.2cm}|}{Execution of\newline Steering and\newline braking} &
		\multicolumn{1}{m{2.4cm}|}{Monitoring of\newline driving\newline environment} &
		\multicolumn{1}{m{2.3cm}|}{Fallback \newline Performance\newline of Dynamic\newline Driving Task}&
		\multicolumn{1}{m{2.4cm}|}{System\newline Capability} \\
	    
	    \hline 
	    \rowcolor{applegreen!50} \multicolumn{6}{|l|}{Human driver monitors the driving environment}\\
		
		\hline
		\rowcolor{applegreen!20} 
		\cellcolor{applegreen!40}0 & 
		\multicolumn{1}{m{2cm}|}{\cellcolor{applegreen!40}No\newline Automation} & 
		Human & 
		Human &
		Human & 
		n.a.\\
		
		\hline
		\rowcolor{applegreen!20} 
		\cellcolor{applegreen!40}1 &
		\multicolumn{1}{m{2cm}|}{\cellcolor{applegreen!40}Driver\newline Assistance} &
		\multicolumn{1}{m{2.2cm}|}{Human \&\newline System} &
		Human &
		Human &
		\multicolumn{1}{m{2.4cm}|}{some\newline driving modes}\\
		
		\hline
		\rowcolor{applegreen!20} 
		\cellcolor{applegreen!40}2 & 
		\multicolumn{1}{m{2cm}|}{\cellcolor{applegreen!40}Partial\newline Automation} &
		System &
		Human &
		Human &
		\multicolumn{1}{m{2.4cm}|}{some\newline driving modes}\\
		
		\hline 
		\rowcolor{ballblue!50} \multicolumn{6}{|l|}{Automated driving system monitors the driving environment}\\
		
		\hline
		\rowcolor{ballblue!20} 
		\cellcolor{ballblue!40}3 &
		\multicolumn{1}{m{2cm}|}{\cellcolor{ballblue!40}Conditional\newline Automation} &
		System &
		System &
		Human &
		\multicolumn{1}{m{2.4cm}|}{some\newline driving modes}\\

		\hline
		\rowcolor{ballblue!20} 
		\cellcolor{ballblue!40}4 & 
		\multicolumn{1}{m{2cm}|}{\cellcolor{ballblue!40}High\newline Automation} &
		System &
		System &
		System &
		\multicolumn{1}{m{2.4cm}|}{some\newline driving modes}\\
		
		\hline
		\rowcolor{ballblue!20} 
		\cellcolor{ballblue!40}5 & 
		\multicolumn{1}{m{2cm}|}{\cellcolor{ballblue!40}Full\newline Automation} &
		System &
		System &
		System &
		\multicolumn{1}{m{2.4cm}|}{all\newline driving modes}\\
		
		\hline
	\end{tabular}
	\caption{\small Summary of level of driving automation \cite{SAE2014}. System refers to the driver assistance system, combination of driver assistance systems, or automated driving system.}
	\label{tab:SAElevel}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{3D Reconstruction}

Generally, the procedure of 3D objects reconstruction consists of feature extraction in image space and depth information recovery in object space. 
To reconstruct the depth information at the exposure moment, either multiple rays spatial intersection or single ray intersection with an elevation model can be applied.
Spatial intersection is usually applied in the cases that the correspondences of the extracted features among different views can be established. Alternatively, when \gls{dem} is available, single extracted feature can be directly projected onto the DEM. In this case, the quality of DEM directly influences the result of 3D object reconstruction. 

\subsection{Feature Extraction and Matching}
The aim of feature extraction is to gain the characteristics of the images, through which the stereo correspondence processes. As a result, the characteristics of the images closely link to the choice of matching methods. % https://en.wikipedia.org/wiki/3D_reconstruction

Blob features have properties of being local intensity maximum or minimum in images. Edge features have image brightness discontinuities in the direction perpendicular to the line direction itself. Variance of algorithms have been proposed for different kinds of features detection. The rotation-invariant Harris corner detector, for example, is commonly used to extract corners and infer features of an image. 

The features are then matched among different views by comparison of the patches which center on the extracted features. Typically the similarity is measured by taking the \gls{ssd} or \gls{ncc} between the corresponding pixels of two patches.% NCC is the simplest but effective affine-illumination-invariant method. 

Scale-Invariant Feature Transform (SIFT) is proposed by \citeauthor{LoweSep1999} in \citeyear{LoweSep1999} \cite{LoweSep1999}. Lowe‘s approach transforms an image into a large collection of local feature vectors, also known as keypoint descriptors. Each SIFT feature descriptor is invariant to image translation, scaling, and rotation, partially invariant to illumination changes and affine or 3D projection. These SIFT keypoints are than matched by identifying their nearest neighbors.


\subsection{\gls{dim}}
Dense image matching performs matching at the actual image resolution, i.e. pixel-wise correspondence between MVS is to be recovered. Depending on image texture, a per-pixel measure is generally ambiguous. Additional constraints, such as the assumption of a smooth surface, need to be introduced. Proposed by \citeauthor{Hirschmueller2008} in \citeyear{Hirschmueller2008}, \gls{sgm} approximates the two-dimensional global aggregation of matching cost by a number of one-dimensional cost path, where the matching step is casted into an energy minimization problem \cite{Hirschmueller2008}. It not only achieves similar accuracy as truly global matching but also significantly reduces computational complexity.
% citation: Semi-Global Matching: An Alternative to LiDAR For DSM Generation?

\section{Automatic Line Detection and Line Matching}

Automatic detected lines may be used for 3D reconstruction by matching lines in the image space. Line matching is challenging for several reasons.

Firstly, line segments may be detected inexactly by automatic line detectors or obstructions appear in part of the lines. Consequently the end-points of a line segment often do not correspond to each other in different views.

Secondly, there is no strong disambiguating geometric constraint available \cite{SchmidJun1997}. In the case of points, correspondences must satisfy the epipolar constraint. This strong disambiguating constraint helps to efficiently reduce the searching space from the whole image (2D) to a single line (1D) in matching processes. In the case of infinite line matching, however, there is no geometric constraint. For lines of finite length, there is only a weak overlap constraint arising from applying the epipolar constraint to its end-points.

Moreover, the corresponding neighborhoods may well have a very different shape and orientation in different views, or even totally different surroundings when dealing with wiry objects \cite{HoferFeb2013}.

In the cases of lane markings, they may be partly shaded by vehicles in aerial images. Besides, the continuous lane lines have no endpoints in the images. Worst of all, the asphalt road surface where the lane markings locate on is poorly textured. Therefore, line matching is even hardly applicable on lane markings.

\section{Related Work}
In the following, some works regarding 3D line reconstruction is presented.

First, appearance-based methods are described. For 3D line reconstruction, \cite{SchmidJun1997,BayJun2005,WangMay2009} have tried to match line segments based on their appearances or some additional geometry constraints.

\citeauthor{SchmidJun1997} exploit the epipolar geometry of line segments and the one-parameter family of homographies to provide point-wise correspondences, allowing cross-correlation of patches around line segments along the candidate lines in the epipolar-beam-region for matching scores evaluation \cite{SchmidJun1997}.

In the cases of poorly textured or shape-changing neighborhood of line segments in different views, line segments are barely comparable using classical correlation patches yet the color neighborhood along this line segment undergoes only slight changes. Based on color histogram rather than textures, \citeauthor{BayJun2005} exploit the appearance similarity of line segment pairs and their topological layout to iteratively increase the correct matches \cite{BayJun2005}. If region matches are available, they are automatically integrated and exploited in combination. The final coplanar grouping stage allows to estimate the fundamental matrix even from line segments only. While color provides a very strong cue for discrimination, it may fail in the case where color feature is not distinctive, e.g. gray images. Besides, although matching groups of line segments takes more geometric information into account for disambiguation, the disadvantage is the increased computational complexity.

Without resorting to any other constraints or prior knowledge, \citeauthor{WangMay2009} propose a purely image content-based line descriptor MSLD for automatic line segments matching. Adapting SIFT-like strategy, MSLD is highly distinctive and robust against image rotation, illumination change, image blur, viewpoint change noise, JPEG compression and partial obstruction \cite{WangMay2009}

The above appearance-based approaches demand either constant and rich neighboring textures or similar color profile of line segments, they are technically matching the surroundings instead of the lines themselves.

In order to create 3D models without the need of explicit line matching, \citeauthor{JainJun2010} generate all possible hypothetical straight 3D line segments by triangulating all the detected straight 2D line segments from different views \cite{JainJun2010}. They then keep the one whose back projection on the gradient images of neighboring views has the highest score, assuming that line features correspond to high gradient areas in images. Built upon the same principles whilst applying epipolar constraint on the end-points of line segments, \citeauthor{HoferFeb2013} generate less hypothetical 3D line segments and thus increase performance significantly while still creating accurate results \cite{HoferFeb2013}. However, both approaches are barely possible in the case of infinite line reconstruction, where the detected 2D lines in different views do not exactly correspond to the same part of a 3D line.

\citeauthor{TaylorNov1995} formulate the Structure from Motion (SfM) problem in terms of minimization of an objective function which measures the total squared distance in the image plane between the observed edge segments and the projections of the reconstructed lines \cite{TaylorNov1995}. By reconstructing the infinite straight line that supports the observed edge segments rather than the end-points of the line, the algorithm can be used even when multiple edges in a single image correspond to different portions of the same 3D line.

\section{Purpose}

In this thesis, I develop a framework to automatically detect the lane markings in the unprojected aerial imagery, and refine the 3D information of the road surface by exploiting the line character of the lane markings.

The unprojected aerial images with their bundle-adjusted orientations and the DSM are the inputs of my algorithm. I apply some standard pre-processing steps and a standard line detection algorithm for automatic lane marking detection in image space. By sliding a window of reasonable length and width through the curved long lane lines, I collect all line segments in all covering images assuming the lane markings to be straight in each sliding window.

I investigate the use of linear regression to optimize the 3D position of each line segments in object space so that its back projection would best fit the detected 2D line in all the covering views, i.e. the position and height of each 3D ane marking segments will be refined in one optimization step. Using the aerial image data set with special flight configuration at both sides of the motorway, the proposed approach addresses the challenging (quasi) infinite and curved properties of lane markings in the 3D reconstruction.

The framework will be tested on aerial imagery from the German highway A9.% and validated with ground measured lane markings by GPS.
